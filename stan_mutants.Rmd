---
title: "Multi-level, Non-linear Bayesian Regression with Stan"
author: "Flynn R. Hill"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(kableExtra)
library(rstan)
```

## The problem



The bell curve is often encountered as the shape of a probability distribution, such as in a histogram of exam scores, however, is relatively uncommon to obtain this shape as a nonlinear function of a predictor variable. In this example, inspired by a real-world problem (the details of which will not be shared in order to protect future Nobel prize winners from being gazumped), several mutant strains of a species of bacteria have been exposed to a range of concentrations of Chemical X. Individual bacteria are exposed, and their response is to either glow green (success) or not. Intriguingly, if we measure a lot of trials over a range of concentrations for a single strain (mutant A, below), we see a bell curve-shaped rise and fall in successes as a function of concentration. We do not have the resources to measure this many trials for each mutant, so we tried to measure 20 trials at each concentration for each mutant instead. However, some of these trials failed due to a technical glitch and the number of trials ranges from 10-20. It looks as if each mutant has a characteristic concentration at which successes peak (the 'centre'), a characteristic fraction of successes at this peak (the 'height') and a characteristic width of the response ('width'). We wish to compare these values for different mutants.



```{r, echo = FALSE, fig.height = 4, fig.width = 9}

set.seed(5646)
gaussian <- function(height,centre,width,x){
  return(height * exp(-0.5* ( ((x - centre)^2)/(width^2)) ))
}

invlogit <- function(x){exp(x)/(1+exp(x))}

exampleconc <- seq(60,80,by = 0.5)

exampleresp_prob <- gaussian(0.5, 70, 1.5, exampleconc)
n_trials <- rbinom(length(exampleconc), size = 100, prob = 0.8)
exampleresp_resp <- rbinom(length(exampleconc), n_trials, prob = exampleresp_prob)

exampleconc2 <- seq(60,80,by = 1)
n_trials2 <- rbinom(length(exampleconc2), size = 16, prob = 0.8)
exampleresp_prob2 <- gaussian(0.4, 65, 1.5, exampleconc2)
exampleresp_resp2 <- rbinom(length(exampleconc2), n_trials2, prob = exampleresp_prob2)


par( mfrow = c(1,2))
plot(exampleconc, exampleresp_resp, xlab = "Concentration", ylab = "Successes", main = "Mutant A (many trials)")
plot(exampleconc2, exampleresp_resp2, xlab = "Concentration", ylab = "Successes", main = "Mutant B (fewer trials)")


```

\  


We are particularly interested in comparing the centre and height values for different mutants, to see how probable it is that they really do differ. But what is the right statistical test for this problem? Multiple t-tests paired at each concentration? ANOVA? But how do these account for the differing numbers of trials? How do they tell us where the centre positions are? I honestly don't know. Instead of trying to figure that out, it will be much easier, and more natural, to fit a probabilistic regression model that describes the shape of the bell curve and accounts for the differing number of trials and stochasticity of the outcome. This model will tell us about the probabilities of all the ways that our dataset could have been obtained, each of which is a unique combination of all the model parameters (i.e. centre, height and width values).


\  

***

\  


## Model

There are two important parts to the model:


1. For each mutant, at each concentration, the observed number of successes $Y$, is drawn from a binomial distribution parameterised by the probability of success $p$ and number of trials. The ~ symbol denotes a stochastic relationship.

$$Y \sim \text{Binomial(trials, } p) $$

2. The true success probabilities $p_j$ for mutant $j$ as a function of concentration $x$ are given by a Gaussian, which is parameterised by the peak height $h_j$ (in units of success probability), peak centre position $c_j$ (in units of concentration), and its width (standard deviation) $\sigma$ (in units of concentration). For simplicity, we are assuming the same width for all mutants. 

$$p_j = h_j \text{ exp}{\frac{-(x-c_j)^2}{2\sigma^2}} $$

Taken together, these allow us to calculate the likelihood of the observed data being generated by a given set of parameters.

\  


A great way to proceed is by simulating some data from this model, and fitting it with a corresponding regression model. In this way, we check our model forwards and backwards - it should simulate data that look like our experimental data, and the regression model should then fit it well. In this way, we gain a deeper appreciation for how the model works, and can much more readily spot flaws in our thinking.


  

\  

***

\  


## Simulation

In this simulation, six mutants will be generated, each with its own height, centre and width parameters. These parameters will each be treated as if they were drawn from common distributions (all strains are of the same species). We start by defining the population mean parameters for height, centre and width. The values for each individual mutant are then drawn from normal distributions centred at these mean values and with standard deviations as given below. The height value is a probability, and therefore ranges between 0 and 1. In order to be able to draw this from a Gaussian distribution, we start off by drawing height values as log odds, which do not have upper and lower bounds, before transforming these to the probability scale.


```{r parameters}


n_mutants <- 6
mutants <- LETTERS[1:n_mutants]  #Give each mutant a name.

# Population-level intercepts
pop_height_logodds <- 0
pop_centre <- 70
pop_width <- 1.5  

# Group level standard deviations (differences between mutants)
group_sd_height_logodds <- 1
group_sd_centre <- 4
group_sd_width <- 0.3


```



\ 

### Random parameter draw

True height and centre parameters for each mutant are now drawn from Gaussian distributions with the population centres and group standard deviations as given above. A random seed is specified to make this reproducible. The height values are in log-odds units, and are transformed to probability using the invlogit function. We can now make a table of the key parameters for each mutant. Note that mutants E and F have the same centre, while mutants B, C and E have the same height value.


```{r random_parameter_draw}

#invlogit function for converting log odds to probability
invlogit <- function(x){exp(x)/(1+exp(x))}

#set height seed for reproducibility
set.seed(100)

mutant_height_logodds <- rnorm(n = n_mutants, mean = pop_height_logodds, sd = group_sd_height_logodds)
mutant_centre <- rnorm(n = n_mutants, mean = pop_centre, sd = group_sd_centre)
mutant_width <- exp(rnorm(n = n_mutants, mean = log(pop_width), sd = group_sd_width))

# Transform these parameters from log-odds to probability
mutant_height_p <- invlogit(mutant_height_logodds)


# Data summary

mutant.frame <- data.frame("mutant" = mutants, "height_logodds" = mutant_height_logodds,   "height_p" = mutant_height_p,"centre" = mutant_centre, "width" = mutant_width)

kable(mutant.frame, format = "html", digits = 1)%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))


```


\  

### Predictor variable and number of trials

The range over which we will measure in our simulated experiment, and the number of trials for each mutant at each concentration.

```{r concentration_trials}

# Predictor variable

conc_range <- 10
conc_interval <- 1
conc <- seq(pop_centre-conc_range, pop_centre + conc_range, conc_interval)
trim = TRUE

# Maximum number of repeats/trials
max_trials = 10

#Probability of max trials
prob_trials = 0.95 #A high value to simulate a situation where there is an intended number of trials, but some have failed for technical reasons.

```



\  

### Probability of success

The Gaussian function is defined and a probability matrix describing the probability of success for each mutant at each tested concentration is calculated, given the parameters height, centre, and width for each mutant.

```{r probability_matrix}

gaussian <- function(height,centre,width,x){
  return(height * exp(-0.5* ( ((x - centre)^2)/(width^2)) ))
}

probability.matrix <- matrix(data = NA, nrow = length(conc), ncol = n_mutants)

for (j in 1:n_mutants){
  for (i in 1:length(conc)){
    probability.matrix[i,j] <- gaussian(mutant_height_p[j], mutant_centre[j], mutant_width[j], conc[i])
    
  }
}
```




### Experiment simulation

For each mutant, at each concentration, the number of trials can vary. Here this is achieved by drawing the number of trials from a binomial distribution (to simulate random technical failures), but that is not crucial to the model.

An experiment is now simulated by drawing from a binomial distribution for each mutant-concentration combination, parameterised the corresponding values from the probabilities matrix and number of trials matrix.


```{r experiment_simulation}

n_trials.matrix <- matrix(data = rbinom(n = length(conc)*n_mutants, size = max_trials, prob = prob_trials),  nrow = length(conc), ncol = n_mutants)

# Simulate experiments - get the number of successes given the probability from the above matrix and the number of trials.
successes.matrix <- matrix(data = NA, nrow = length(conc), ncol = n_mutants)

for (j in 1:n_mutants){
  for (i in 1:length(conc)){
    successes.matrix[i,j] <- rbinom(1, prob =  probability.matrix[i,j], size = n_trials.matrix[i,j])
    
  }
}

```



\  

### Reshape data

We now make use of the tidyverse set of packages. Data are reformatted from a wide format in which each mutant has its own column to [tidy format](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html), which is easier to work with. In this long table format we have a single column to specify the mutant, and single columns for concentration, number of trials and number of successes. For convenience, we also tack on columns with the true mutant parameters (these values are simply repeated in each row for the same mutant). If you look at the ggplot function below, you will see the advantage that tidy format confers - we can now describe the plot for all mutants at once, rather than having to add layers for each mutant.


```{r reshape_data}
# Bring all the data together
n_trials.frame <- as.data.frame(n_trials.matrix)
colnames(n_trials.frame) <- mutants
n_trials.frame$conc <- conc

n_trials.frame.gathered <- gather(n_trials.frame, mutant, n_trials, -conc)

prob.frame <- as.data.frame(probability.matrix)
colnames(prob.frame) <- mutants
prob.frame$conc <- conc

prob.frame.gathered <- gather(prob.frame, mutant, probability, -conc)

successes.frame <- as.data.frame(successes.matrix)
colnames(successes.frame) <- mutants
successes.frame$conc <- conc


# Tidy format and combine
successes.frame.gathered <- gather(successes.frame, mutant, successes, -conc) %>%
  left_join(n_trials.frame.gathered) %>%
  left_join(prob.frame.gathered) %>%
  left_join(mutant.frame)


if (trim == TRUE){
  #Trim away the zero readings.
  successes.frame.gathered <- successes.frame.gathered %>%
    filter(conc > centre - 4*width & conc < centre + 4*width)

}

```


\  

And this is how our simulated measurements look:

```{r plot_simulation, fig.width = 9}
# Plot
ggplot(successes.frame.gathered)+
  aes(x = conc, y = successes/n_trials, group = mutant)+
  geom_vline(data = mutant.frame, aes(xintercept = centre), linetype = "dashed")+
  geom_line(aes(y = n_trials/max_trials), linetype = "dashed", colour = "grey")+
  geom_line(aes(y = probability), colour = "blue")+
  geom_point(size = 1)+
  theme_bw(14)+
  facet_wrap(~mutant,ncol=2)+
  labs(x = "Concentration", caption = paste0("Horizontal dashed line represents number of trials as fraction of maximum trials (", max_trials, ").\nVertical dashed line shows the true centre.\nBlue curve shows the true probability."))

```


\  

***

\  


## Stan model

Here we are using the tidy format data as the input. The mutants are named by an index rather than letter. All input data must be packaged together in a list.


```{r stan_data}

mlist <- data.frame("mutant" = mutants, mutant_num = seq(1:n_mutants))

successes.frame.gathered <- successes.frame.gathered %>% left_join(mlist)

dat_allmutants = list(
  J = n_mutants,
  N = nrow(successes.frame.gathered),
  mutant = successes.frame.gathered$mutant_num,
  x = successes.frame.gathered$conc,
  n_trials = successes.frame.gathered$n_trials,
  y = successes.frame.gathered$successes
)

```


\  


The stan model is stored in a separate .stan file, however, it is also possible to provide it as a string. It is split into blocks as follows, shown individually for convenience. See the Stan manual for more information. 

### Data block

```{Rcpp, eval = FALSE}
data {
  int<lower=1> J; //number of mutants
  int<lower=1> N; //Number of observations
  int<lower=1,upper=J> mutant[N]; //mutant for observation n
  vector[N] x; //concentration for observation n
  int<lower=0> n_trials[N]; //number of trials for observation n
  int<lower=0> y[N]; //Number of survivors for observation n
}

```

Values in the data block should match what we have put in our data list. The choice of type for each variable in the data block is crucial, and the Stan manual is very helpful in this area. Having said that, I am still a bit hazy on the choice between vectors and arrays. With vectors, I believe it should be possible to express the for loop that calculates psurvive in the model block as a single vectorised line of code, and that should improve the speed of the model (not that speed is an issue in this particular case), however, I am uncertain how to achieve this.

### Parameters block

```{Rcpp, eval = FALSE}
parameters {
  real mu_centre;
  real<lower=0> sigma_centre;
  vector[J] centre_raw;

  real mu_heightlogodds;
  real<lower=0> sigma_heightlogodds;
  vector[J] heightlogodds_raw;

  real<lower=0> mu_width_squared;
  real<lower=0> sigma_width_squared;
  vector[J] width_raw_squared;
}
```

These are the parameters to be estimated by the regression fit. The parameters for each mutant are loosely treated as coming from common distributions. A population centre value is estimated, along with a scaling value. Individual mutant deviations are then drawn from centred unit normals. The mutant parameter is then given in the transformed parameters block as the mutant deviation times the scaling factor plus the population centre value. 

Although I have used the word 'centre' a lot, this is actually the 'non-centred' parameterisation. The Stan manual does a good job of explaining this, but here's my attempt: In the centred parameterisation, individual mutant parameters are drawn directly from a distribution with an estimated population centre and standard deviation. The problem with the centred parameterisation is that the population centre, standard deviation and individual mutant values are highly correlated. When there is a large change in the population centre value, the individual mutant values must be sampled from the low probability region in the far reaches of the prior in order to compensate. The advantage of the non-centred parametrisation is that it places less constraint on the individual mutant values, which are sampled from the unit normal no matter where the population centre value is placed. If there were many mutants, the centred parameterisation can be more efficient, as the population centre is more accurately determined and will be consistent through draws. Because we are dealing with only a small number of mutants, the non-centred paramterisation works best.

Note that because the width parameter only appears as its square in the gaussian formula, it is simplified to width_squared here, so that Stan doesn't waste time squaring negative values of width. 

### Transformed parameters block

```{Rcpp, eval = FALSE}
transformed parameters {
  vector[J] height;
  vector[J] centre;
  vector[J] heightlogodds;
  vector<lower=0>[J] width_squared;

  centre = mu_centre + sigma_centre*centre_raw;

  heightlogodds = mu_heightlogodds + sigma_heightlogodds * heightlogodds_raw;

  height = inv_logit(heightlogodds);

  width_squared = mu_width_squared + sigma_width_squared * width_raw_squared;
}
```

Here, individual centre, height and width_squared values for each mutant are calculated as the population centre value plus the individual mutant's deviation times the scaling factor. 

### Model block

```{Rcpp, eval = FALSE}
model {
  vector[N] psurvive;
  for (n in 1:N)
    psurvive[n] = height[mutant[n]] * exp( -0.5* ( ((x[n] - centre[mutant[n]])^2) / (width_squared[mutant[n]]) ) );

  mu_centre ~ normal(65,20); 
  sigma_centre ~ cauchy(0,2);
  centre_raw ~ normal(0,1);

  mu_heightlogodds ~ normal(0.5,2);
  sigma_heightlogodds ~ cauchy(0,2);
  heightlogodds_raw ~ normal(0,1);

  mu_width_squared ~ cauchy(0,5);
  sigma_width_squared ~ cauchy(0,3);
  width_raw_squared ~ normal(0,1);

  y ~ binomial(n_trials, psurvive);
}
```

Here, prior probability distributions are specified for each parameter, as well as the likelihood. The likelihood is given by 'y ~ binomial(n_trials, psurvive)' in conjunction with the loop that gives psurvive values at each mutant/concentration combination.

### Generated quantities block

```{Rcpp, eval = FALSE}
generated quantities {

  vector<lower=0>[J] width;
  width = sqrt(width_squared);
}
```

Here, the width is output as the square root of the width_squared parameter. This is output purely for convenience, and is not used in the model. If we wanted to, we could define the gaussian formula here and output success probabilities over a range of concentrations for each mutant in each draw, however, this would end up being a lot of data, and we can do this afterwards for just a subset of draws.


\  

***

\  

### Run the model

In this case, the model is very fast. The slowest parts are compiling the model, and finding initial values that do not conflict with the parameter restrictions (e.g. non-negative values of width_squared). But it still only takes about 20 seconds in total. If this had been too much of a problem, it is possible to specify initial values (different values must be supplied to each chain).


```{r run_stan, results = 'hide', cache = TRUE}
fit <- stan(file = "mutant_model.stan", 
            model_name = "example",
            data = dat_allmutants, 
            iter = 2000, warmup = 1000, chains = 4, cores = 4, sample_file = 'multi_mutants.csv',
verbose = FALSE)

```

\  

I am not going to devote the space here to investigating how well the model ran - convergence etc., but I will recommend that Shinystan is an excellent package for exploring these issues.

```{r, eval=FALSE}
library(shinystan)
launch_shinystan(fit)
```


\  

Now plot the posterior distributions of values of the centre parameter.


```{r plot_centre, fig.height = 4, fig.width = 9}
plot(fit, pars = "centre")
```

Most pairs of mutants are distinct, however, mutants A and C have partially overlapping distributions, while mutants E and F have completely overlapping distributions. We will need to delve further into the posterior draws to assess these.


\  

***

\  



## Posterior draws

Extract some example posterior draws (note that these start from the first post-warmup draw) and calculate the corresponding probability curves given by the parameters in each draw. To get nice looking curves we will sample concentrations at finer intervals than we did in our experiment. Note that the package Bayesplot can do all of this (including supplying a custom function of the parameters, such as the gaussian), but for the sake of learning I have gone through this manually.

```{r posterior_draws, fig.width = 9}

n_draws <- 200

draws <- paste0("draw_", 1:n_draws)

list_of_draws <- extract(fit, pars = c("centre", "height", "width"))

centrevals <- as.data.frame(list_of_draws$centre[1:n_draws,])
colnames(centrevals) <- mutants

widthvals <- as.data.frame(list_of_draws$width[1:n_draws,])
colnames(widthvals) <- mutants

heightvals <- as.data.frame(list_of_draws$height[1:n_draws,])
colnames(heightvals) <- mutants

conc_detailed <- seq(60,80,0.1)

#Create a 3D array of draw-mutant-concentration, filled with the probability of success.
curves <- array(NA, dim=c(n_draws, n_mutants, length(conc_detailed)), dimnames = list(draws, mutants, conc_detailed))
for (i in 1:n_draws){
  for (j in 1:n_mutants){
    for (k in 1:length(conc_detailed)){
      curves[i,j,k] <- gaussian(height = heightvals[i,j], centre = centrevals[i,j], width = widthvals[i,j], x = conc_detailed[k]) 
    }
  }
}

#Turn the array into a data frame in tidy format - the fastest way is to use the melt function from reshape2 (unfortunately tidyr's 'gather' does not work on arrays)
library(reshape2)
curves_c <- melt(curves)
detach(package:reshape2)

colnames(curves_c) <- c("draw", "mutant", "conc", "prob")

```


\  

Make some functions to plot the posterior draws.

```{r plotting_functions}

fPaste <- function(vec) sub(",\\s+([^,]+)$", " and \\1", toString(vec)) #A function from stack exchange by Arun Kirshna (akrun) that gives comma separated lists, with an 'and' before the final item.

#A function to plot some draws in separate facets
compare_mutants_plot <- function(mutantlist, draws_to_plot=12, centre_draws = centrevals, curvedata = curves_c){
  
  centrepositions <- centre_draws[1:draws_to_plot,] %>%
  mutate(draw = draws[1:draws_to_plot]) %>%
  gather(mutant, centre,-draw)
  
  outplot <- curvedata %>%
  filter(mutant %in% mutantlist) %>%
  filter(draw %in% draws[1:draws_to_plot]) %>%
  ggplot()+
  aes(x = conc, y = prob, group = mutant, colour = mutant)+
  geom_line()+
  geom_vline(data = centrepositions %>% filter(mutant %in% mutantlist), aes(xintercept = centre, colour = mutant))+
  facet_wrap(~draw)+
  scale_colour_manual(values = c("blue", "darkorange"))+
  labs(title = paste0("Fitted curves for mutants ", fPaste(mutantlist), ": ", draws_to_plot, " posterior draws"),x = "Concentration", y = "Probability of success")+
  theme(legend.position = "bottom")
  
  return(outplot)
}

#A function to overlay many draws

overlay_mutants_plot <- function(mutantlist, draws_to_plot=200, curvedata = curves_c){
  outplot <- curvedata %>%
    filter(mutant %in% mutantlist) %>%
  ggplot()+
    aes(x = conc, y = prob, group = interaction(mutant, draw), colour = mutant)+
    geom_line(alpha = 0.3)+
    scale_colour_manual(values = c("blue", "darkorange"))+
    labs(title = paste0("Fitted curves for mutants ", fPaste(mutantlist), ": ", draws_to_plot, " posterior draws"), x = "Concentration", y = "Probability of success")+
    theme(legend.position = "bottom")
  return(outplot)
}

#A function to plot the distribution of differences between centre values
difference_plot <- function(first_mutant = "A", second_mutant = "C", parameter = "centre", drawlist = list_of_draws){
  
  first = match(first_mutant, mutants)
  second = match(second_mutant, mutants)
  
  first_mutant_draws <- drawlist[[parameter]][,first]
  second_mutant_draws <- drawlist[[parameter]][,second]
  
  outplot <- data.frame("difference" = first_mutant_draws - second_mutant_draws) %>%
  ggplot()+
  aes(x = difference)+
  stat_density(geom = "line", colour = "blue")+
    labs(title = paste0("Distribution of differences of mutants ", first_mutant, " and ", second_mutant, " ", parameter, " values: 4000 posterior draws"), x = "Difference")
  
  return(outplot)
  }

```

\  

### Mutants A and C

Notably, from the plot above we can see that mutants A and C have partially overlapping distributions. Does this mean our model is implying that A and C could possibly share the same (or a very very close) value for centre? Not necessarily - to be able to make a statement about this we need to make comparisons within draws only. Let's get a quick idea of how these look:
 
```{r a_c_facet, fig.width = 9}

compare_mutants_plot(c("A", "C"), 12)

```


But that was just a few draws, here are many more:

```{r a_c_overlay, fig.width=9}
overlay_mutants_plot(c("A", "C"))

```

But this is still only a subset of the draws. We have done thousands more post-warmup draws, let's compare across all of them. Mutant A appears to have a slightly higher peak centre value. In what fraction of draws is the peak centre of mutant A at a higher concentration than the peak centre of mutant C?

```{r compare_all_draws}

centre_a.all <- list_of_draws$centre[,1]
centre_c.all <- list_of_draws$centre[,3]

sum(centre_a.all > centre_c.all)/length(centre_a.all)

```

`r round(100*sum(centre_a.all > centre_c.all)/length(centre_a.all), 1)`% of them. So, while we can see that they have very close centre values, mutant A probably has a greater centre value than mutant C. Indeed, we know that the true centre value for mutant A is 1.0 concentration units greater than that of C. We can go one better still, and plot the distribution of their differences in all draws.


```{r, fig.width = 9, fig.height = 4}

difference_plot("A", "C")
```

The median difference is `r round(median(centre_a.all - centre_c.all),1)`, a slight underestimate. Looking at the experimental data, there is one concentration point for mutant A to the left of its peak centre value at which an unusually high number of trials were successful, given the underlying probability. This would have the effect of dragging the estimated peak centre to the left. So we are within a regime where we get pretty good estimates, but are of course subject to stochasticity and a bit more data would help. The important point here is that we now have in hand a probability distribution for the difference between these values, rather than a single maximum likelihood estimation, which given the stochastic relationship between paramaters and observations is vastly preferable.

\  

### Mutants E and F


What about mutants E and F? The distributions for their centre values are entirely overlapping, and we know that their true centre values are identical.

```{r e_f_facet, fig.width = 9}
compare_mutants_plot(c("E", "F"), 12)

```



```{r e_f_overlay, fig.width=9}
overlay_mutants_plot(c("E", "F"))

```



In what fraction of draws is the peak centre of mutant F at a lower concentration than the peak centre of mutant E?

```{r compare_all_draws2}

centre_e.all <- list_of_draws$centre[,5]
centre_f.all <- list_of_draws$centre[,6]

sum(centre_f.all < centre_e.all)/length(centre_f.all)


```


Mutant F, which is has a true peak centre identical to mutant E was lower than mutant E in approximately half of the draws, so we would not say that there is evidence they differ.

```{r, fig.width = 9, fig.height = 4}

difference_plot("E", "F")
```

\  

So, the model is looking good, it did a good job with the simulated data. The next step would be to fit it to the actual experimental data.


Making this has been a learning experience for me, and I hope that it was helpful for you.

\  



***


\  



